{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8afcc21e-866f-4b8d-8722-a7a525c16d86",
   "metadata": {},
   "source": [
    "### Load the network for transer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78f2140c-fd6f-44ef-ad5a-7dab67cd65bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "def create_model():\n",
    "    local_weights_file = './inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "# Initialize the base model.\n",
    "# Set the input shape and remove the dense layers.\n",
    "    pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None)\n",
    "\n",
    "# Load the pre-trained weights you downloaded.\n",
    "    pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Freeze the weights of the layers.\n",
    "    for layer in pre_trained_model.layers:\n",
    "      layer.trainable = False\n",
    "    \n",
    "    #choose mixed7 as the final convo layer\n",
    "    last_layer=pre_trained_model.get_layer('mixed7')\n",
    "    last_output=last_layer.output\n",
    "    \n",
    "    #create the model that we will use by adding some dense layers\n",
    "    from tensorflow.keras.optimizers import RMSprop\n",
    "    from tensorflow.keras import Model\n",
    "\n",
    "    # Flatten the output layer to 1 dimension\n",
    "    x=layers.Flatten()(last_output)\n",
    "\n",
    "    # Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "    x=layers.Dense(1024,activation='relu')(x)\n",
    "\n",
    "    # Add a dropout rate of 0.2\n",
    "    x = layers.Dropout(0.2)(x)      \n",
    "\n",
    "    # Add a final sigmoid layer for classification\n",
    "    x = layers.Dense  (1, activation='sigmoid')(x)           \n",
    "\n",
    "    # Append the dense network to the base model\n",
    "    model = Model(pre_trained_model.input, x) \n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab86f7a9-2d53-496b-95fc-b8bcd4af518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set the weights file you downloaded into a variable\n",
    "local_weights_file = './inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "# Initialize the base model.\n",
    "# Set the input shape and remove the dense layers.\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None)\n",
    "\n",
    "# Load the pre-trained weights you downloaded.\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Freeze the weights of the layers.\n",
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5889d9bf-6a2d-4286-9416-073138537269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose mixed7 as the final convo layer\n",
    "last_layer=pre_trained_model.get_layer('mixed7')\n",
    "last_output=last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b383129-620e-4e0f-b961-d1fac6076bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model that we will use by adding some dense layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x=layers.Flatten()(last_output)\n",
    "\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x=layers.Dense(1024,activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)      \n",
    "\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
    "\n",
    "# Append the dense network to the base model\n",
    "model = Model(pre_trained_model.input, x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "086512b1-89cc-4e2c-bc0b-a7fb0bf5147a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c7f434-7633-4a06-9d8c-b3a6d305b9e3",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f72544a-348b-43f4-be7e-96fcfe7b4b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Define our example directories and files\n",
    "base_dir = './cats_and_dogs_filtered'\n",
    "\n",
    "train_dir = os.path.join( base_dir, 'train')\n",
    "validation_dir = os.path.join( base_dir, 'validation')\n",
    "\n",
    "# Directory with training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats') \n",
    "\n",
    "# Directory with training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs') \n",
    "\n",
    "# Directory with validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats') \n",
    "\n",
    "# Directory with validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary', \n",
    "                                                    target_size = (150, 150))     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                          batch_size  = 20,\n",
    "                                                          class_mode  = 'binary', \n",
    "                                                          target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed16474a-debe-4799-ab15-db4964c54b4c",
   "metadata": {},
   "source": [
    "### Set the callback func so that weights of the model will be saved every 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b4055cb-2254-4020-a163-ebb84a2b783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer = RMSprop(learning_rate=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c69f1012-b47b-41b7-8df3-646a5790a2e3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 40/100 [===========>..................] - ETA: 12s - loss: 0.4752 - accuracy: 0.8325\n",
      "Epoch 00001: saving model to training_2\\cp-0001.ckpt\n",
      " 80/100 [=======================>......] - ETA: 5s - loss: 0.3935 - accuracy: 0.8506\n",
      "Epoch 00001: saving model to training_2\\cp-0001.ckpt\n",
      "100/100 [==============================] - 39s 310ms/step - loss: 0.3669 - accuracy: 0.8590 - val_loss: 0.0867 - val_accuracy: 0.9680\n",
      "Epoch 2/20\n",
      " 20/100 [=====>........................] - ETA: 12s - loss: 0.2135 - accuracy: 0.9100\n",
      "Epoch 00002: saving model to training_2\\cp-0002.ckpt\n",
      " 60/100 [=================>............] - ETA: 7s - loss: 0.2370 - accuracy: 0.9050\n",
      "Epoch 00002: saving model to training_2\\cp-0002.ckpt\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2189 - accuracy: 0.9125\n",
      "Epoch 00002: saving model to training_2\\cp-0002.ckpt\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.2189 - accuracy: 0.9125 - val_loss: 0.0949 - val_accuracy: 0.9690\n",
      "Epoch 3/20\n",
      " 40/100 [===========>..................] - ETA: 9s - loss: 0.1670 - accuracy: 0.9325\n",
      "Epoch 00003: saving model to training_2\\cp-0003.ckpt\n",
      " 80/100 [=======================>......] - ETA: 3s - loss: 0.1928 - accuracy: 0.9262\n",
      "Epoch 00003: saving model to training_2\\cp-0003.ckpt\n",
      "100/100 [==============================] - 23s 225ms/step - loss: 0.2028 - accuracy: 0.9215 - val_loss: 0.1026 - val_accuracy: 0.9700\n",
      "Epoch 4/20\n",
      " 20/100 [=====>........................] - ETA: 12s - loss: 0.1956 - accuracy: 0.9300\n",
      "Epoch 00004: saving model to training_2\\cp-0004.ckpt\n",
      " 60/100 [=================>............] - ETA: 7s - loss: 0.2023 - accuracy: 0.9325\n",
      "Epoch 00004: saving model to training_2\\cp-0004.ckpt\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.2110 - accuracy: 0.9270\n",
      "Epoch 00004: saving model to training_2\\cp-0004.ckpt\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 0.2110 - accuracy: 0.9270 - val_loss: 0.1081 - val_accuracy: 0.9660\n",
      "Epoch 5/20\n",
      " 40/100 [===========>..................] - ETA: 9s - loss: 0.1603 - accuracy: 0.9375\n",
      "Epoch 00005: saving model to training_2\\cp-0005.ckpt\n",
      " 80/100 [=======================>......] - ETA: 3s - loss: 0.1706 - accuracy: 0.9356\n",
      "Epoch 00005: saving model to training_2\\cp-0005.ckpt\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 0.1697 - accuracy: 0.9395 - val_loss: 0.1069 - val_accuracy: 0.9660\n",
      "Epoch 6/20\n",
      " 20/100 [=====>........................] - ETA: 12s - loss: 0.1389 - accuracy: 0.9525\n",
      "Epoch 00006: saving model to training_2\\cp-0006.ckpt\n",
      " 60/100 [=================>............] - ETA: 8s - loss: 0.1751 - accuracy: 0.9433\n",
      "Epoch 00006: saving model to training_2\\cp-0006.ckpt\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1679 - accuracy: 0.9390\n",
      "Epoch 00006: saving model to training_2\\cp-0006.ckpt\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.1679 - accuracy: 0.9390 - val_loss: 0.1328 - val_accuracy: 0.9620\n",
      "Epoch 7/20\n",
      " 40/100 [===========>..................] - ETA: 9s - loss: 0.1550 - accuracy: 0.9463 - ETA: 11s - loss: 0.1568 - \n",
      "Epoch 00007: saving model to training_2\\cp-0007.ckpt\n",
      " 80/100 [=======================>......] - ETA: 3s - loss: 0.1810 - accuracy: 0.9312\n",
      "Epoch 00007: saving model to training_2\\cp-0007.ckpt\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 0.1673 - accuracy: 0.9375 - val_loss: 0.1027 - val_accuracy: 0.9690\n",
      "Epoch 8/20\n",
      " 20/100 [=====>........................] - ETA: 12s - loss: 0.2208 - accuracy: 0.9125\n",
      "Epoch 00008: saving model to training_2\\cp-0008.ckpt\n",
      " 60/100 [=================>............] - ETA: 7s - loss: 0.1920 - accuracy: 0.9258\n",
      "Epoch 00008: saving model to training_2\\cp-0008.ckpt\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1873 - accuracy: 0.9270\n",
      "Epoch 00008: saving model to training_2\\cp-0008.ckpt\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 0.1873 - accuracy: 0.9270 - val_loss: 0.1140 - val_accuracy: 0.9650\n",
      "Epoch 9/20\n",
      " 40/100 [===========>..................] - ETA: 9s - loss: 0.1702 - accuracy: 0.9488\n",
      "Epoch 00009: saving model to training_2\\cp-0009.ckpt\n",
      " 80/100 [=======================>......] - ETA: 3s - loss: 0.1602 - accuracy: 0.9475\n",
      "Epoch 00009: saving model to training_2\\cp-0009.ckpt\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 0.1737 - accuracy: 0.9470 - val_loss: 0.0994 - val_accuracy: 0.9640\n",
      "Epoch 10/20\n",
      " 20/100 [=====>........................] - ETA: 12s - loss: 0.1228 - accuracy: 0.9525\n",
      "Epoch 00010: saving model to training_2\\cp-0010.ckpt\n",
      " 60/100 [=================>............] - ETA: 7s - loss: 0.1417 - accuracy: 0.9517\n",
      "Epoch 00010: saving model to training_2\\cp-0010.ckpt\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1493 - accuracy: 0.9510\n",
      "Epoch 00010: saving model to training_2\\cp-0010.ckpt\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.1493 - accuracy: 0.9510 - val_loss: 0.1607 - val_accuracy: 0.9550\n",
      "Epoch 11/20\n",
      " 40/100 [===========>..................] - ETA: 8s - loss: 0.1322 - accuracy: 0.9538\n",
      "Epoch 00011: saving model to training_2\\cp-0011.ckpt\n",
      " 80/100 [=======================>......] - ETA: 3s - loss: 0.1336 - accuracy: 0.9506\n",
      "Epoch 00011: saving model to training_2\\cp-0011.ckpt\n",
      "100/100 [==============================] - 22s 221ms/step - loss: 0.1566 - accuracy: 0.9455 - val_loss: 0.1095 - val_accuracy: 0.9690\n",
      "Epoch 12/20\n",
      " 20/100 [=====>........................] - ETA: 11s - loss: 0.1066 - accuracy: 0.9625\n",
      "Epoch 00012: saving model to training_2\\cp-0012.ckpt\n",
      " 60/100 [=================>............] - ETA: 7s - loss: 0.1583 - accuracy: 0.9508\n",
      "Epoch 00012: saving model to training_2\\cp-0012.ckpt\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1377 - accuracy: 0.9520\n",
      "Epoch 00012: saving model to training_2\\cp-0012.ckpt\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 0.1377 - accuracy: 0.9520 - val_loss: 0.1464 - val_accuracy: 0.9570\n",
      "Epoch 13/20\n",
      " 40/100 [===========>..................] - ETA: 8s - loss: 0.1360 - accuracy: 0.9513\n",
      "Epoch 00013: saving model to training_2\\cp-0013.ckpt\n",
      " 80/100 [=======================>......] - ETA: 3s - loss: 0.1609 - accuracy: 0.9469\n",
      "Epoch 00013: saving model to training_2\\cp-0013.ckpt\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 0.1613 - accuracy: 0.9465 - val_loss: 0.0864 - val_accuracy: 0.9710\n",
      "Epoch 14/20\n",
      " 20/100 [=====>........................] - ETA: 11s - loss: 0.1371 - accuracy: 0.9550\n",
      "Epoch 00014: saving model to training_2\\cp-0014.ckpt\n",
      " 60/100 [=================>............] - ETA: 7s - loss: 0.1397 - accuracy: 0.9550\n",
      "Epoch 00014: saving model to training_2\\cp-0014.ckpt\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1356 - accuracy: 0.9570\n",
      "Epoch 00014: saving model to training_2\\cp-0014.ckpt\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 0.1356 - accuracy: 0.9570 - val_loss: 0.1712 - val_accuracy: 0.9520\n",
      "Epoch 15/20\n",
      " 40/100 [===========>..................] - ETA: 9s - loss: 0.1041 - accuracy: 0.9588\n",
      "Epoch 00015: saving model to training_2\\cp-0015.ckpt\n",
      " 80/100 [=======================>......] - ETA: 3s - loss: 0.1150 - accuracy: 0.9569\n",
      "Epoch 00015: saving model to training_2\\cp-0015.ckpt\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 0.1282 - accuracy: 0.9550 - val_loss: 0.1321 - val_accuracy: 0.9640\n",
      "Epoch 16/20\n",
      " 20/100 [=====>........................] - ETA: 11s - loss: 0.1337 - accuracy: 0.9575\n",
      "Epoch 00016: saving model to training_2\\cp-0016.ckpt\n",
      " 60/100 [=================>............] - ETA: 7s - loss: 0.1313 - accuracy: 0.9583\n",
      "Epoch 00016: saving model to training_2\\cp-0016.ckpt\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1489 - accuracy: 0.9505\n",
      "Epoch 00016: saving model to training_2\\cp-0016.ckpt\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.1489 - accuracy: 0.9505 - val_loss: 0.1320 - val_accuracy: 0.9660\n",
      "Epoch 17/20\n",
      " 40/100 [===========>..................] - ETA: 8s - loss: 0.0860 - accuracy: 0.9625\n",
      "Epoch 00017: saving model to training_2\\cp-0017.ckpt\n",
      " 80/100 [=======================>......] - ETA: 3s - loss: 0.1397 - accuracy: 0.9563\n",
      "Epoch 00017: saving model to training_2\\cp-0017.ckpt\n",
      "100/100 [==============================] - 22s 222ms/step - loss: 0.1357 - accuracy: 0.9580 - val_loss: 0.1479 - val_accuracy: 0.9560\n",
      "Epoch 18/20\n",
      " 20/100 [=====>........................] - ETA: 11s - loss: 0.1209 - accuracy: 0.9600\n",
      "Epoch 00018: saving model to training_2\\cp-0018.ckpt\n",
      " 60/100 [=================>............] - ETA: 7s - loss: 0.1284 - accuracy: 0.9575\n",
      "Epoch 00018: saving model to training_2\\cp-0018.ckpt\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1247 - accuracy: 0.9575\n",
      "Epoch 00018: saving model to training_2\\cp-0018.ckpt\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.1247 - accuracy: 0.9575 - val_loss: 0.1270 - val_accuracy: 0.9700\n",
      "Epoch 19/20\n",
      " 40/100 [===========>..................] - ETA: 9s - loss: 0.1719 - accuracy: 0.9438\n",
      "Epoch 00019: saving model to training_2\\cp-0019.ckpt\n",
      " 80/100 [=======================>......] - ETA: 3s - loss: 0.1411 - accuracy: 0.9531\n",
      "Epoch 00019: saving model to training_2\\cp-0019.ckpt\n",
      "100/100 [==============================] - 22s 223ms/step - loss: 0.1370 - accuracy: 0.9575 - val_loss: 0.1230 - val_accuracy: 0.9680\n",
      "Epoch 20/20\n",
      " 20/100 [=====>........................] - ETA: 10s - loss: 0.1918 - accuracy: 0.9475\n",
      "Epoch 00020: saving model to training_2\\cp-0020.ckpt\n",
      " 60/100 [=================>............] - ETA: 7s - loss: 0.1445 - accuracy: 0.9533\n",
      "Epoch 00020: saving model to training_2\\cp-0020.ckpt\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.1365 - accuracy: 0.9575\n",
      "Epoch 00020: saving model to training_2\\cp-0020.ckpt\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.1365 - accuracy: 0.9575 - val_loss: 0.1006 - val_accuracy: 0.9710\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Include the epoch in the file name (uses `str.format`)\n",
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "# Create a callback that saves the model's weights every 2 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq=2*batch_size)\n",
    "\n",
    "\n",
    "\n",
    "# Save the weights using the `checkpoint_path` format\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "# Train the model with the new callback\n",
    "\n",
    "history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = 100,\n",
    "            epochs = 20,\n",
    "            validation_steps = 50,\n",
    "            callbacks=[cp_callback],\n",
    "            verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f19786a6-ed5f-41b9-9495-e82d23a6b2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checkpoint',\n",
       " 'cp-0000.ckpt.data-00000-of-00001',\n",
       " 'cp-0000.ckpt.index',\n",
       " 'cp-0001.ckpt.data-00000-of-00001',\n",
       " 'cp-0001.ckpt.index',\n",
       " 'cp-0002.ckpt.data-00000-of-00001',\n",
       " 'cp-0002.ckpt.index',\n",
       " 'cp-0003.ckpt.data-00000-of-00001',\n",
       " 'cp-0003.ckpt.index',\n",
       " 'cp-0004.ckpt.data-00000-of-00001',\n",
       " 'cp-0004.ckpt.index',\n",
       " 'cp-0005.ckpt.data-00000-of-00001',\n",
       " 'cp-0005.ckpt.index',\n",
       " 'cp-0006.ckpt.data-00000-of-00001',\n",
       " 'cp-0006.ckpt.index',\n",
       " 'cp-0007.ckpt.data-00000-of-00001',\n",
       " 'cp-0007.ckpt.index',\n",
       " 'cp-0008.ckpt.data-00000-of-00001',\n",
       " 'cp-0008.ckpt.index',\n",
       " 'cp-0009.ckpt.data-00000-of-00001',\n",
       " 'cp-0009.ckpt.index',\n",
       " 'cp-0010.ckpt.data-00000-of-00001',\n",
       " 'cp-0010.ckpt.index',\n",
       " 'cp-0011.ckpt.data-00000-of-00001',\n",
       " 'cp-0011.ckpt.index',\n",
       " 'cp-0012.ckpt.data-00000-of-00001',\n",
       " 'cp-0012.ckpt.index',\n",
       " 'cp-0013.ckpt.data-00000-of-00001',\n",
       " 'cp-0013.ckpt.index',\n",
       " 'cp-0014.ckpt.data-00000-of-00001',\n",
       " 'cp-0014.ckpt.index',\n",
       " 'cp-0015.ckpt.data-00000-of-00001',\n",
       " 'cp-0015.ckpt.index',\n",
       " 'cp-0016.ckpt.data-00000-of-00001',\n",
       " 'cp-0016.ckpt.index',\n",
       " 'cp-0017.ckpt.data-00000-of-00001',\n",
       " 'cp-0017.ckpt.index',\n",
       " 'cp-0018.ckpt.data-00000-of-00001',\n",
       " 'cp-0018.ckpt.index',\n",
       " 'cp-0019.ckpt.data-00000-of-00001',\n",
       " 'cp-0019.ckpt.index',\n",
       " 'cp-0020.ckpt.data-00000-of-00001',\n",
       " 'cp-0020.ckpt.index']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac255d-68c7-455f-8249-e6e1108fcd4d",
   "metadata": {},
   "source": [
    "### Check the accuracy of model with handpicked image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2084f487-35e8-4662-9b89-9b31c2aadc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model with weights saved in epoch 13\n",
    "model_epoch_13=create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7abc895b-077a-4390-b4b9-0ac198db3d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_epoch_13.compile(optimizer = RMSprop(learning_rate=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06939f54-1db8-4522-9ee2-d3d1d7037c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x23edc6db040>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path_epoch_13 = \"training_2/cp-0013.ckpt\"\n",
    "# Loads the weights\n",
    "model_epoch_13.load_weights(checkpoint_path_epoch_13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2281d47-c652-447a-b5f0-2fa7daf1e598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 - 2s - loss: 0.1006 - accuracy: 0.9710\n",
      "Restored model, accuracy: 97.10%\n"
     ]
    }
   ],
   "source": [
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(validation_generator, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "504508b3-89a1-42dd-92cf-286868d0151d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d2462ffd9b4ac4a00dcf87c95c9eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, description='Upload', multiple=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import FileUpload\n",
    "upload=FileUpload(multiple=True)\n",
    "display(upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f13c7c23-4b94-41f3-844f-439a0398948b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00065097]\n",
      "cat sleeping on couch 4.jpg is a cat\n",
      "[9.839734e-05]\n",
      "cat sleeping on couch 5.jpg is a cat\n",
      "[0.9997191]\n",
      "cat sleeping on couch.jpg is a dog\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "for fn in upload.value.keys():\n",
    "    path=os.path.join('./test/',fn)\n",
    "    img=image.load_img(path,target_size=(150,150))\n",
    "    x=image.img_to_array(img)\n",
    "    x/=255\n",
    "    x=np.expand_dims(x,axis=0)\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict(images, batch_size=10)\n",
    "    print(classes[0])\n",
    "    \n",
    "    if classes[0]>0.5:\n",
    "        print(fn + \" is a dog\")\n",
    "        \n",
    "    else:\n",
    "        print(fn + \" is a cat\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67e3bff4-8232-456c-b89d-0431101fc8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7723841]\n",
      "cat sleeping on couch 4.jpg is a dog\n",
      "[5.879124e-06]\n",
      "cat sleeping on couch 5.jpg is a cat\n",
      "[0.99999475]\n",
      "cat sleeping on couch.jpg is a dog\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "for fn in upload.value.keys():\n",
    "    path=os.path.join('./test/',fn)\n",
    "    img=image.load_img(path,target_size=(150,150))\n",
    "    x=image.img_to_array(img)\n",
    "    x/=255\n",
    "    x=np.expand_dims(x,axis=0)\n",
    "    images = np.vstack([x])\n",
    "    classes = model_epoch_13.predict(images, batch_size=10)\n",
    "    print(classes[0])\n",
    "    \n",
    "    if classes[0]>0.5:\n",
    "        print(fn + \" is a dog\")\n",
    "        \n",
    "    else:\n",
    "        print(fn + \" is a cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6befe19-b416-47d9-a843-176f20ece674",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
